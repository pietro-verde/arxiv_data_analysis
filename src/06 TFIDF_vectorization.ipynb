{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06489f4f-1c01-4afe-9750-08298f00e1f5",
   "metadata": {},
   "source": [
    "# TF-IDF feature extraction\n",
    "\n",
    "Feature engineering is a large focus of research NLP. Text cannot be fed directly into a machine learning model. Therefore, we need some kind of numerical representation.\n",
    "\n",
    "Bag-of-words (BOW) is a farily old but still somewhat popular feature engineering method for text. In this approach, a vocabulary of all the unique words in the corpus is created and each document is represented as a vector of\n",
    "word counts. This method ignores the order of words in the text but can still be effective for many NLP tasks. In fact, this is the method used the n-gram analysis on the arXiv dataset in the previous notebook. A version of this can use bigrams or even additional number of words taken together in sequence.\n",
    "\n",
    "Term frequency-inverse document frequency (TF-IDF) is a variation of BOW where instead of a simple count, a weight is used, representing the importance of words in a document. Words that appear frequently in a document and rarely in others are given a relatively higher weight compared to more common words.\n",
    "\n",
    "The calculation for TF-IDF is the following:\n",
    "\n",
    "For each word taken from a document belonging to a set of documents,\n",
    "TF = (count of word / total words) in the same document\n",
    "IDF = log(total count of documents / count of documents that contain the word)\n",
    "TF-IDF = TF * IDF\n",
    "\n",
    "where TF stands for Term Frequency in document and IDF for Inverse Document Frequency.\n",
    "\n",
    "In this notebook, a TfidfVectorizer is fitted on the trainining data. The resulting model is used to create feature vectors out of the train, validation and testing data.\n",
    "\n",
    "Two versions of the TF-IDF vectorization model are trained. One considering single words only and the others considering unigrams and bigrams.\n",
    "\n",
    "The max number of features is limited to 10000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f78750ab-6db9-4a01-9640-1399fa73c32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fedb6a7c-c34f-4ae1-8dfa-fe0f353e8d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "THIS_MODEL_NAME = 'TFIDF'\n",
    "VERSION = '1'\n",
    "\n",
    "OUTPUT_DIR = '../data/wip/'+THIS_MODEL_NAME+'/'\n",
    "for dir_ in [OUTPUT_DIR]:\n",
    "    if not os.path.exists(dir_):\n",
    "        os.makedirs(dir_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47d338ff-e8b6-4045-9980-b5a37990d9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE = \"../data/data.parquet.gzip\"\n",
    "data = pd.read_parquet(FILE, columns=['target','processed_docs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20afe745-104d-4289-9afc-0118b6272ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = pickle.load(open(\"../data/wip/train_idx.pkl\", 'rb'))\n",
    "val_idx = pickle.load(open(\"../data/wip/val_idx.pkl\", 'rb'))\n",
    "test_idx = pickle.load(open(\"../data/wip/test_idx.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03718a6b-f11d-446d-b735-f7dcf222a20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = data.loc[train_idx]\n",
    "validation_data = data.loc[val_idx]\n",
    "testing_data = data.loc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e145969f-a196-4afa-a7cf-17a3eb7d13fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20611c67-7b19-4441-8042-1176ad9afc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = 'processed_docs'\n",
    "target = 'target'\n",
    "\n",
    "X_train_raw = training_data[features]\n",
    "X_val_raw = validation_data[features]\n",
    "X_test_raw = testing_data[features]\n",
    "\n",
    "y_train = training_data[target]\n",
    "y_val = validation_data[target]\n",
    "y_test = testing_data[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a8c5f94-5f03-4e2f-be9a-9d778b450f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_ranges=[(1,1), (1,2)]\n",
    "labels = [\"X_train\", \"X_val\", \"X_test\"]\n",
    "Xsets = [X_train_raw, X_val_raw, X_test_raw]\n",
    "\n",
    "for nr in ngram_ranges:\n",
    "    nr_lable = str(nr[0])+\"_\"+str(nr[1])\n",
    "    vectorizer = TfidfVectorizer(ngram_range=nr, max_features = 10_000)\n",
    "    for label, X in zip(labels, Xsets):\n",
    "        if(label == \"X_train\"):\n",
    "            vectorizer.fit(X)\n",
    "        name = THIS_MODEL_NAME+\"_\"+label+\"_\"+nr_lable\n",
    "        vectors = vectorizer.transform(X)\n",
    "        with open(OUTPUT_DIR+name+'.pkl', 'wb') as f:\n",
    "            pickle.dump(vectors, f)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7adb9019-b8f2-4937-ab79-576447f023dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"y_train\", \"y_val\", \"y_test\"]\n",
    "ysets = [y_train, y_val, y_test]\n",
    "\n",
    "for label, y in zip(labels, ysets):\n",
    "    name = THIS_MODEL_NAME+\"_\"+label+\"_\"\n",
    "    with open(OUTPUT_DIR+name+'.pkl', 'wb') as f:\n",
    "        pickle.dump(y, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
